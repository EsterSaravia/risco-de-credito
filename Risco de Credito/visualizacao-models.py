# -*- coding: utf-8 -*-
"""visualizacao.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17qmD9fZ52yiMlptxIjUZ-b0lJtKFa0hx
"""

# importar pandas e tabelas
import pandas as pd
df = pd.read_csv('merged.csv')

# Verificar informações sobre os dados
print("Infomaçao de Dados:")
print(df.info())

#importar bibliotecas
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
# Balancear cria amostras sintéticas da classe minoritária
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import GridSearchCV
import numpy as np

"""LIME (Local Interpretable Model-agnostic Explanations): Explica as **previsões de forma local**, ou seja, para instâncias individuais. Ele fornece uma explicação compreensível de como o modelo chegou a uma determinada previsão para uma observação específica.

**LIME** explica localmente: Mostra a **influência das características** para uma única observação.
"""

!pip install lime

!pip install eli5

#importa modelo
from sklearn.ensemble import RandomForestClassifier

# Convertendo variáveis categóricas em numéricas
le = LabelEncoder()
df['sex'] = le.fit_transform(df['sex'])
df['clean_loan_type'] = le.fit_transform(df['clean_loan_type'])

# Preenchendo valores ausentes
df.fillna(df.median(), inplace=True)

# Dividir os dados em conjunto de treinamento e teste
#X = df[['more_90_days_overdue', 'number_times_delayed_payment_loan_30_59_days', 'age', 'number_times_delayed_payment_loan_60_89_days', 'total_loan', 'number_dependents_median']]
X = df[['more_90_days_overdue', 'age', 'total_loan', 'number_dependents_median']]
y = df['default_flag']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Normalizar dados
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Criar e treinar o modelo de Random Forest
rf_model = RandomForestClassifier(random_state=42)
rf_model.fit(X_train, y_train)

# Fazer previsões e avaliar o modelo de Random Forest
y_pred_rf = rf_model.predict(X_test)
print("\nRandom Forest:")
print("Accuracy:", accuracy_score(y_test, y_pred_rf))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred_rf))
print("\nClassification Report:\n", classification_report(y_test, y_pred_rf))

# Visualizar a matriz de confusão
conf_matrix = confusion_matrix(y_test, y_pred_rf)
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Não Inadimplente', 'Inadimplente'], yticklabels=['Não Inadimplente', 'Inadimplente'])
plt.xlabel('Previsão')
plt.ylabel('Verdadeiro')
plt.title('Matriz de Confusão - Random Forest')
plt.show()

# Aplicar SMOTE apenas no conjunto de treinamento para balancear
smote = SMOTE(random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

# Treinar o modelo de Random Forest novamente com os dados balanceados
rf_model_balanced = RandomForestClassifier(random_state=42)
rf_model_balanced.fit(X_train_resampled, y_train_resampled)

# Fazer previsões e avaliar o modelo de Random Forest após balanceamento
y_pred_rf_balanced = rf_model_balanced.predict(X_test)

# Imprimir métricas de avaliação após balanceamento
print("\nApos balanceamento Random Forest:")
print("Accuracy:", accuracy_score(y_test, y_pred_rf_balanced))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred_rf_balanced))
print("\nClassification Report:\n", classification_report(y_test, y_pred_rf_balanced))

# Visualizar a matriz de confusão após balanceamento
conf_matrix_balanced = confusion_matrix(y_test, y_pred_rf_balanced)
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix_balanced, annot=True, fmt='d', cmap='Blues', xticklabels=['Não Inadimplente', 'Inadimplente'], yticklabels=['Não Inadimplente', 'Inadimplente'])
plt.xlabel('Previsão')
plt.ylabel('Verdadeiro')
plt.title('Matriz de Confusão - Random Forest (Apos Balanceamento SMOTE)')
plt.show()

# Fazer previsões e avaliar o modelo de Árvore de Decisão apos
#y_pred_dt = rf_model.predict(X_test)
#print("\n Apos balanceamento Random Forest:")
#print("Accuracy:", accuracy_score(y_test, y_pred_dt))
#print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred_dt))
#print("\nClassification Report:\n", classification_report(y_test, y_pred_dt))

# Obter a importância das variáveis
importances = rf_model_balanced.feature_importances_
indices = np.argsort(importances)[::-1]

# Nome das variáveis
#feature_names = ['Mais de 90 dias em atraso', 'Atraso de 30-59 dias', 'Idade', 'Atraso de 60-89 dias', 'Total de Empréstimos', 'Número de Dependentes']
feature_names = ['Mais de 90 dias em atraso', 'Idade', 'Total de Empréstimos', 'Número de Dependentes']

# Plotar a importância das variáveis
plt.figure(figsize=(10, 6))
plt.title('Importância das Variáveis Global - Random Forest')
plt.bar(range(X_train.shape[1]), importances[indices], align='center')
plt.xticks(range(X_train.shape[1]), [feature_names[i] for i in indices], rotation=45)
plt.xlabel('Variáveis')
plt.ylabel('Importância')
plt.show()

import lime
import lime.lime_tabular
from IPython.display import display, HTML

# Criar um explicador LIME
explainer = lime.lime_tabular.LimeTabularExplainer(X_train, feature_names=feature_names, class_names=['Não Inadimplente', 'Inadimplente'], discretize_continuous=True)

# Escolher uma observação para explicar
i = 0
exp = explainer.explain_instance(X_test[i], rf_model_balanced.predict_proba, num_features=len(feature_names))

# Obter o HTML da explicação
exp_html = exp.as_html()

# Adicionar título e customizar estilo
custom_html = f"""
    <div style="font-family: Arial; font-size: 16px; color: white;">
        <h2 style="font-weight: bold;">Explicação da Previsão Local</h2>
        {exp_html}
    </div>
"""

# Mostrar o HTML customizado
display(HTML(custom_html))

from sklearn.inspection import PartialDependenceDisplay

# Plotar Partial Dependence Plots
fig, ax = plt.subplots(figsize=(12, 8))
#PartialDependenceDisplay.from_estimator(rf_model, X_train, features=[0, 1, 2, 3, 4, 5], feature_names=feature_names, ax=ax)
PartialDependenceDisplay.from_estimator(rf_model_balanced, X_train, features=[0, 1, 2, 3], feature_names=feature_names, ax=ax)
plt.suptitle('Gráficos de dependência parcial - Random Forest')
plt.subplots_adjust(top=0.9)  # ajustar a posição do título
plt.show()

import eli5
from eli5.sklearn import PermutationImportance
import matplotlib.pyplot as plt
from IPython.display import display, HTML

# Treinar o modelo de Random Forest novamente (se necessário)
rf_model_balanced.fit(X_train, y_train)

# Usar PermutationImportance para calcular a importância das variáveis
perm = PermutationImportance(rf_model_balanced, random_state=42).fit(X_test, y_test)

# Gerar a importância das variáveis usando eli5
weights_html = eli5.show_weights(perm, feature_names=feature_names).data

# Adicionar título e customizar estilo
custom_html = f"""
    <div style="font-family: Arial; font-size: 16px; color: black;">
        <h2 style="font-weight: bold;">Importância das Variáveis usando Permutation Importance</h2>
        {weights_html}
    </div>
"""

# Mostrar o HTML customizado
display(HTML(custom_html))

from sklearn.model_selection import learning_curve, KFold

def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None, n_jobs=None, train_sizes=np.linspace(0.1, 1.0, 10)):
    plt.figure()
    plt.title(title)
    if ylim is not None:
        plt.ylim(*ylim)
    plt.xlabel("Exemplos de treinamento")
    plt.ylabel("Pontuação")
    train_sizes, train_scores, test_scores = learning_curve(
        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)
    train_scores_mean = np.mean(train_scores, axis=1)
    train_scores_std = np.std(train_scores, axis=1)
    test_scores_mean = np.mean(test_scores, axis=1)
    test_scores_std = np.std(test_scores, axis=1)
    plt.grid()

    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,
                     train_scores_mean + train_scores_std, alpha=0.1,
                     color="r")
    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,
                     test_scores_mean + test_scores_std, alpha=0.1, color="g")
    plt.plot(train_sizes, train_scores_mean, 'o-', color="r",
             label="Desempenho treinamento")
    plt.plot(train_sizes, test_scores_mean, 'o-', color="g",
             label="Desempenho validação cruzada")

    plt.legend(loc="best")
    return plt

title = "Curvas de Aprendizagem (Random Forest)"
cv = KFold(n_splits=5)
plot_learning_curve(rf_model_balanced, title, X_train_resampled, y_train_resampled, cv=cv)
plt.show()

# Convertendo variáveis categóricas em numéricas
le = LabelEncoder()
df['sex'] = le.fit_transform(df['sex'])
df['clean_loan_type'] = le.fit_transform(df['clean_loan_type'])

# Preenchendo valores ausentes
df.fillna(df.median(), inplace=True)

# Dividir os dados em conjunto de treinamento e teste
#X = df[['more_90_days_overdue', 'number_times_delayed_payment_loan_30_59_days', 'age', 'number_times_delayed_payment_loan_60_89_days', 'total_loan', 'number_dependents_median']]
X = df[['more_90_days_overdue', 'age', 'total_loan', 'number_dependents_median']]
y = df['default_flag']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Normalizar dados
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Criar e treinar o modelo de regressão logística
model = LogisticRegression()
model.fit(X_train, y_train)

# Fazer previsões e avaliar o modelo
y_pred = model.predict(X_test)

# Imprimir resultados
print("Resultados com dados Normalizados: ")
print("\nAcurácia do modelo:", accuracy_score(y_test, y_pred))
print("\nMatriz de Confusão:\n", confusion_matrix(y_test, y_pred))
print("\nRelatório de Classificação:\n", classification_report(y_test, y_pred))

# Visualizar a matriz de confusão
plt.figure(figsize=(8, 6))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues', xticklabels=['Não Inadimplente', 'Inadimplente'], yticklabels=['Não Inadimplente', 'Inadimplente'])
plt.xlabel('Previsão')
plt.ylabel('Verdadeiro')
plt.title('Matriz de Confusão - Regressão Logística')
plt.show()

# Aplicar SMOTE apenas no conjunto de treinamento para balancear
smote = SMOTE(random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

#O GridSearchCV é uma ferramenta poderosa para encontrar os melhores hiperparâmetros para um modelo, ajudando a otimizar seu desempenho.
# Definir os parâmetros para a busca em grade
param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'penalty': ['l1', 'l2']}

# Criar o objeto GridSearchCV
grid_search = GridSearchCV(model, param_grid, cv=5)

# Realizar a busca em grade de hiperparâmetros
grid_search.fit(X_train_resampled, y_train_resampled)

# Usar o modelo resultante da busca em grade
model = grid_search.best_estimator_

# Fazer previsões e avaliar o modelo
y_pred = model.predict(X_test)

# Imprimir resultados finais
print("\nResultados após a otimização dos hiperparâmetros e Balanceamento de classes: ")
print("\nMelhores parâmetros encontrados:", grid_search.best_params_)
print("\nAcurácia do modelo após otimização:", accuracy_score(y_test, y_pred))
print("\nMatriz de Confusão após otimização:\n", confusion_matrix(y_test, y_pred))
print("\nRelatório de Classificação após otimização:\n", classification_report(y_test, y_pred))

# Visualizar a matriz de confusão após otimização
plt.figure(figsize=(8, 6))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues', xticklabels=['Não Inadimplente', 'Inadimplente'], yticklabels=['Não Inadimplente', 'Inadimplente'])
plt.xlabel('Previsão')
plt.ylabel('Verdadeiro')
plt.title('Matriz de Confusão - Regressão Logística (Após Otimização)')
plt.show()

"""Coeficiente das Variáveis (Coefficients): Mostra a **importância global** de cada variável no modelo. Geralmente usado em modelos lineares como regressão logística."""

# Obter os coeficientes das variáveis
coefficients = model.coef_[0]

feature_names = [
    'Mais de 90 dias em atraso',
    'Idade',
    'Total de Empréstimos',
    'Número de Dependentes'
]

# Plotar os coeficientes das variáveis
plt.figure(figsize=(10, 6))
plt.title('Importância Global no Modelo - Regressão Logística')
bars = plt.bar(range(len(coefficients)), coefficients, align='center')
plt.xticks(range(len(coefficients)), feature_names, rotation=45)  # Usar os nomes das variáveis como rótulos
plt.xlabel('Variáveis')
plt.ylabel('Coeficientes')

# Adicionar rótulos às barras
for bar, coef in zip(bars, coefficients):
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width() / 2, height, f'{coef:.2f}', ha='center', va='bottom', fontsize=8)

plt.tight_layout()
plt.show()

# Plotar os coeficientes das variáveis
coefficients = model.coef_[0]
feature_names = [
    'Mais de 90 dias em atraso',
    'Mais de 30 dias em atraso',
    'Idade',
    'Mais de 60 dias em atraso',
    'Total de Empréstimos',
    'Número de Dependentes'
]

plt.figure(figsize=(8, 6))
plt.title('Importância Global no Modelo - Regressão Logística', fontsize=16)
bars = plt.bar(range(len(coefficients)), coefficients, align='center', color=np.where(coefficients > 0, 'royalblue', 'tomato'))
plt.xticks(range(len(coefficients)), feature_names, rotation=45, ha='right', fontsize=12)  # Usar os nomes das variáveis como rótulos
plt.xlabel('Variáveis', fontsize=14)
plt.ylabel('Coeficientes', fontsize=14)

# Adicionar linha horizontal em y=0
plt.axhline(0, color='black', linewidth=0.8)

# Adicionar rótulos às barras
for bar, coef in zip(bars, coefficients):
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width() / 2, height, f'{coef:.2f}', ha='center', va='bottom', fontsize=10, color='black')

plt.grid(True, linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

import lime
import lime.lime_tabular

# Criar um explicador LIME
explainer = lime.lime_tabular.LimeTabularExplainer(X_train,
                                                   feature_names=feature_names,
                                                   class_names=['Não Inadimplente', 'Inadimplente'],
                                                   discretize_continuous=True)

# Escolher uma observação para explicar
i = 1
exp = explainer.explain_instance(X_test[i], model.predict_proba, num_features=len(feature_names))

# Visualizar a explicação
exp.show_in_notebook(show_table=True, show_all=False)

# Melhorias visuais e informações adicionais
print("\nExplicação:")
print("Probabilidades de previsão:")
print("Não Inadimplente:", exp.predict_proba[0])
print("Inadimplente:", exp.predict_proba[1])
print("\nRecursos e Valores:")
for feature, value in exp.as_list():
    print(f"{feature}: {value}")

"""Gráfico de Dependência Parcial (Partial Dependence Plots): Ajuda a entender como uma variável específica **afeta as previsões do modelo** enquanto mantém as outras variáveis constantes. Isso permite explorar as relações entre as variáveis de entrada e a variável de saída."""

from sklearn.inspection import PartialDependenceDisplay

# Plotar Partial Dependence Plots
fig, ax = plt.subplots(figsize=(12, 8))
display = PartialDependenceDisplay.from_estimator(model, X_train, features=[0, 1, 2, 3], feature_names=feature_names, ax=ax)
display.figure_.suptitle('Gráficos de dependência parcial - Regressão Logística', fontsize=16, fontweight='bold', y=1.02)
#plt.ylabel('Efeito na Previsão', fontsize=12)
plt.subplots_adjust(top=0.9)  # ajustar a posição do título
plt.show()

"""Eli5 (Explain Like I'm 5): Ajuda a entender quais variáveis estão **contribuindo mais para as previsões** do modelo usando métodos de interpretabilidade de modelos, como a importância de permutação."""

import eli5
from eli5.sklearn import PermutationImportance
from IPython.display import HTML

# Treinar o modelo de Random Forest novamente (se necessário)
model.fit(X_train, y_train)

# Usar PermutationImportance para calcular a importância das variáveis
perm = PermutationImportance(model, random_state=42).fit(X_test, y_test)

# Mostrar a importância das variáveis com título e texto em preto
weights_html = eli5.show_weights(perm, feature_names=feature_names).data

# Adicionar um título
styled_weights_html = f"<h3 style='color: black;'>contribuição para previsões</h3>{weights_html}"

# Adicionando estilo para trocar a cor do texto para preto
styled_weights_html = styled_weights_html.replace('<style>', '<style>body {color: black !important;} ')

# Mostrando a importância das variáveis com título e texto em preto
HTML(styled_weights_html)

from sklearn.metrics import roc_curve, auc, roc_auc_score

# Calcular as probabilidades previstas para a classe positiva (1)
y_pred_prob = model.predict_proba(X_test)[:, 1]

# Calcular a curva ROC
fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)

# Calcular a área sob a curva (AUC)
roc_auc = auc(fpr, tpr)

# Plotar a curva ROC
plt.figure(figsize=(10, 8))
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Taxa Falsamente Positiva')
plt.ylabel('Taxa Verdadeiramente Positiva')
plt.title('Desempenho do Modelo de Classificação (ROC)')
plt.legend(loc="lower right")
plt.show()

# Calcular e imprimir o AUC
print("\nÁrea sob a Curva (AUC):", roc_auc)

# Interpretar a AUC
if roc_auc >= 0.9:
    print("\nAUC excelente - o modelo é capaz de distinguir muito bem entre as classes positiva e negativa.")
elif roc_auc >= 0.8:
    print("\nAUC bom - o modelo é capaz de distinguir bem entre as classes positiva e negativa.")
elif roc_auc >= 0.7:
    print("\nAUC razoável - o modelo é capaz de distinguir moderadamente entre as classes positiva e negativa.")
else:
    print("\nAUC fraco - o modelo não é capaz de distinguir bem entre as classes positiva e negativa.")

from sklearn.model_selection import learning_curve, KFold

def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None, n_jobs=None, train_sizes=np.linspace(0.1, 1.0, 8)):
    plt.figure()
    plt.title(title)
    if ylim is not None:
        plt.ylim(*ylim)
    plt.xlabel("Exemplos de treinamento")
    plt.ylabel("Pontuação")
    train_sizes, train_scores, test_scores = learning_curve(
        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)
    train_scores_mean = np.mean(train_scores, axis=1)
    train_scores_std = np.std(train_scores, axis=1)
    test_scores_mean = np.mean(test_scores, axis=1)
    test_scores_std = np.std(test_scores, axis=1)
    plt.grid()

    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,
                     train_scores_mean + train_scores_std, alpha=0.1,
                     color="r")
    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,
                     test_scores_mean + test_scores_std, alpha=0.1, color="g")
    plt.plot(train_sizes, train_scores_mean, 'o-', color="r",
             label="Desempenho treinamento")
    plt.plot(train_sizes, test_scores_mean, 'o-', color="g",
             label="Desempenho validação cruzada")

    plt.legend(loc="best")
    return plt

title = "Curvas de Aprendizagem (Logistic Regression SMOTE)"
cv = KFold(n_splits=5)
plot_learning_curve(model, title, X_train_resampled, y_train_resampled, cv=cv)
plt.show()

# Definir os modelos
models = {
    'Regressão Logística': LogisticRegression(C=100, penalty='l2'),
    'Árvore de decisão': DecisionTreeClassifier(),
    'Random Forest': RandomForestClassifier()
}

# Dividir os dados em conjunto de treinamento e teste
X = df[['more_90_days_overdue', 'age', 'total_loan', 'number_dependents_median']]
y = df['default_flag']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Aplicar SMOTE apenas no conjunto de treinamento
smote = SMOTE(random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

# Lista para armazenar as acurácias
accuracies = []

# Treinar e avaliar cada modelo
for name, model in models.items():
    model.fit(X_train_resampled, y_train_resampled)
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    accuracies.append(accuracy)
    print(f"{name}: Accuracy = {accuracy}")

# Plotar o gráfico de barras das acurácias
plt.figure(figsize=(10, 6))
plt.barh(np.arange(len(models)), accuracies, color='skyblue')
plt.yticks(np.arange(len(models)), models.keys())
plt.xlabel('Precisão')
plt.title('Precisão de diferentes modelos')
plt.gca().invert_yaxis()  # Inverter a ordem dos modelos no eixo y para que o modelo com a maior acurácia fique no topo
plt.show()

#importa modelo de arvore e desisao
from sklearn.tree import DecisionTreeClassifier

# Convertendo variáveis categóricas em numéricas
le = LabelEncoder()
df['sex'] = le.fit_transform(df['sex'])
df['clean_loan_type'] = le.fit_transform(df['clean_loan_type'])

# Preenchendo valores ausentes
df.fillna(df.median(), inplace=True)

# Dividir os dados em conjunto de treinamento e teste
X = df[['more_90_days_overdue', 'age', 'total_loan', 'number_dependents_median']]
y = df['default_flag']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Normalizar dados
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Criar e treinar o modelo de Árvore de Decisão
dt_model = DecisionTreeClassifier(random_state=42)
dt_model.fit(X_train, y_train)

# Fazer previsões e avaliar o modelo de Árvore de Decisão
y_pred_dt = dt_model.predict(X_test)
print("Decision Tree:")
print("Accuracy:", accuracy_score(y_test, y_pred_dt))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred_dt))
print("\nClassification Report:\n", classification_report(y_test, y_pred_dt))

# Visualizar a matriz de confusão
plt.figure(figsize=(8, 6))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues', xticklabels=['Não Inadimplente', 'Inadimplente'], yticklabels=['Não Inadimplente', 'Inadimplente'])
plt.xlabel('Previsão')
plt.ylabel('Verdadeiro')
plt.title('Matriz de Confusão - Árvore de Decisão')
plt.show()

# Aplicar SMOTE apenas no conjunto de treinamento
smote = SMOTE(random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

# Fazer previsões e avaliar o modelo de Árvore de Decisão apos
y_pred_dt = dt_model.predict(X_test)
print("\n Apos balanceamento decision Tree:")
print("Accuracy:", accuracy_score(y_test, y_pred_dt))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred_dt))
print("\nClassification Report:\n", classification_report(y_test, y_pred_dt))

# Visualizar a matriz de confusão após otimização
plt.figure(figsize=(8, 6))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues', xticklabels=['Não Inadimplente', 'Inadimplente'], yticklabels=['Não Inadimplente', 'Inadimplente'])
plt.xlabel('Previsão')
plt.ylabel('Verdadeiro')
plt.title('Matriz de Confusão - Árvore de Decisão (Após Otimização)')
plt.show()

import matplotlib.pyplot as plt
import numpy as np

# Obter a importância das variáveis
importances = dt_model.feature_importances_
indices = np.argsort(importances)[::-1]

# Nome das variáveis
#feature_names = ['Mais de 90 dias em atraso', 'Atraso de 30-59 dias', 'Idade', 'Atraso de 60-89 dias', 'Total de Empréstimos', 'Número de Dependentes']
feature_names = ['Mais de 90 dias em atraso', 'Idade', 'Total de Empréstimos', 'Número de Dependentes']

# Plotar a importância das variáveis
plt.figure(figsize=(10, 6))
plt.title('Importância das Variáveis Global - Árvore de Decisão')
plt.bar(range(X_train.shape[1]), importances[indices], align='center')
plt.xticks(range(X_train.shape[1]), [feature_names[i] for i in indices], rotation=45)
plt.xlabel('Variáveis')
plt.ylabel('Importância')
plt.show()

from sklearn.inspection import PartialDependenceDisplay

# Plotar Partial Dependence Plots
fig, ax = plt.subplots(figsize=(12, 8))
#PartialDependenceDisplay.from_estimator(rf_model, X_train, features=[0, 1, 2, 3, 4, 5], feature_names=feature_names, ax=ax)
PartialDependenceDisplay.from_estimator(dt_model, X_train, features=[0, 1, 2, 3], feature_names=feature_names, ax=ax)
plt.suptitle('Gráficos de dependência parcial - Random Forest')
plt.subplots_adjust(top=0.9)  # ajustar a posição do título
plt.show()

import lime
import lime.lime_tabular
from IPython.display import display, HTML

# Criar um explicador LIME
explainer = lime.lime_tabular.LimeTabularExplainer(X_train, feature_names=feature_names, class_names=['Não Inadimplente', 'Inadimplente'], discretize_continuous=True)

# Escolher uma observação para explicar
i = 1
exp = explainer.explain_instance(X_test[i], dt_model.predict_proba, num_features=len(feature_names))

# Obter o HTML da explicação
exp_html = exp.as_html()

# Adicionar título e customizar estilo
custom_html = f"""
    <div style="font-family: Arial; font-size: 16px; color: white;">
        <h2 style="font-weight: bold;">Explicação da Previsão Local</h2>
        {exp_html}
    </div>
"""

# Mostrar o HTML customizado
display(HTML(custom_html))

import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import learning_curve, KFold

def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None, n_jobs=None, train_sizes=np.linspace(0.1, 1.0, 8)):
    plt.figure()
    plt.title(title)
    if ylim is not None:
        plt.ylim(*ylim)
    plt.xlabel("Exemplos de treinamento")
    plt.ylabel("Pontuação")
    train_sizes, train_scores, test_scores = learning_curve(
        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)
    train_scores_mean = np.mean(train_scores, axis=1)
    train_scores_std = np.std(train_scores, axis=1)
    test_scores_mean = np.mean(test_scores, axis=1)
    test_scores_std = np.std(test_scores, axis=1)
    plt.grid()

    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,
                     train_scores_mean + train_scores_std, alpha=0.1,
                     color="r")
    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,
                     test_scores_mean + test_scores_std, alpha=0.1, color="g")
    plt.plot(train_sizes, train_scores_mean, 'o-', color="r",
             label="Desempenho treinamento")
    plt.plot(train_sizes, test_scores_mean, 'o-', color="g",
             label="Desempenho validação cruzada")

    plt.legend(loc="best")
    return plt

title = "Curvas de Aprendizagem (Logistic Regression SMOTE)"
cv = KFold(n_splits=5)
plot_learning_curve(dt_model, title, X_train_resampled, y_train_resampled, cv=cv)
plt.show()

"""**Com Variavel dummy**"""

# importar pandas e tabelas
import pandas as pd
df = pd.read_csv('dummy.csv')

# Verificar informações sobre os dados
print("Infomaçao de Dados:")
print(df.info())

#Dividir os dados em conjunto de treinamento e teste
X = df[['idade_risco', 'dias90_risco', 'dias60_risco', 'dias30_risco', 'empretismo_risco', 'salario_risco', 'dependente_risco', 'uso_limite_risco']]
y = df['classificacao'] # variavel dependente
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Criar e treinar o modelo de regressão logística
model_dummy = LogisticRegression()
model_dummy.fit(X_train, y_train)

# Fazer previsões e avaliar o modelo
y_pred = model_dummy.predict(X_test)

#imprimir resultados

print("Acurácia do modelo:", accuracy_score(y_test, y_pred))
print("\nMatriz de Confusão:\n", confusion_matrix(y_test, y_pred))
print("\nRelatório de Classificação:\n", classification_report(y_test, y_pred))


# Visualizar a matriz de confusão
plt.figure(figsize=(8, 6))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues', xticklabels=['Não Inadimplente', 'Inadimplente'], yticklabels=['Não Inadimplente', 'Inadimplente'])
plt.xlabel('Previsão')
plt.ylabel('Verdadeiro')
plt.title('Matriz de Confusão - Regressão Logística')
plt.show()

# Obter os coeficientes das variáveis
coefficients = model_dummy.coef_[0]

feature_names = ['idade_risco', 'dias90_risco', 'dias60_risco', 'dias30_risco', 'empretismo_risco', 'dependente_risco', 'uso_limite_risco', 'salario_risco']

# Plotar os coeficientes das variáveis
plt.figure(figsize=(10, 6))
plt.title('Importância Global no Modelo - Regressão Logística')
bars = plt.bar(range(len(coefficients)), coefficients, align='center')
plt.xticks(range(len(coefficients)), feature_names, rotation=45)  # Usar os nomes das variáveis como rótulos
plt.xlabel('Variáveis')
plt.ylabel('Coeficientes')

# Adicionar rótulos às barras
for bar, coef in zip(bars, coefficients):
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width() / 2, height, f'{coef:.2f}', ha='center', va='bottom', fontsize=8)

plt.tight_layout()
plt.show()

# Criar um DataFrame com os coeficientes e os nomes das variáveis
coef_df = pd.DataFrame({'feature': X.columns, 'coefficient': model_dummy.coef_[0]})
# Ordenar o DataFrame pelos coeficientes em ordem absoluta decrescente
coef_df['abs_coefficient'] = coef_df['coefficient'].abs()  # Adicionando coluna com os coeficientes em valor absoluto
coef_df = coef_df.sort_values('abs_coefficient', ascending=False)

# Exibir o DataFrame com os coeficientes das variáveis
print(coef_df)

from sklearn.inspection import PartialDependenceDisplay

# Plotar Partial Dependence Plots
fig, ax = plt.subplots(figsize=(12, 10))
PartialDependenceDisplay.from_estimator(model_dummy, X_train, features=[0, 1, 2, 3, 4, 5, 6, 7], feature_names=feature_names, ax=ax)
plt.suptitle('Gráficos de dependência parcial - Random Forest')
plt.subplots_adjust(top=0.9)  # ajustar a posição do título
plt.show()

from sklearn.metrics import roc_curve, auc, roc_auc_score

# Calcular as probabilidades previstas para a classe positiva (1)
y_pred_prob = model_dummy.predict_proba(X_test)[:, 1]

# Calcular a curva ROC
fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)

# Calcular a área sob a curva (AUC)
roc_auc = auc(fpr, tpr)

# Plotar a curva ROC
plt.figure(figsize=(10, 8))
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Taxa Falsamente Positiva')
plt.ylabel('Taxa Verdadeiramente Positiva')
plt.title('Desempenho do Modelo de Classificação (ROC)')
plt.legend(loc="lower right")
plt.show()

# Calcular e imprimir o AUC
print("\nÁrea sob a Curva (AUC):", roc_auc)

# Interpretar a AUC
if roc_auc >= 0.9:
    print("\nAUC excelente - o modelo é capaz de distinguir muito bem entre as classes positiva e negativa.")
elif roc_auc >= 0.8:
    print("\nAUC bom - o modelo é capaz de distinguir bem entre as classes positiva e negativa.")
elif roc_auc >= 0.7:
    print("\nAUC razoável - o modelo é capaz de distinguir moderadamente entre as classes positiva e negativa.")
else:
    print("\nAUC fraco - o modelo não é capaz de distinguir bem entre as classes positiva e negativa.")

from sklearn.model_selection import learning_curve, KFold

def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None, n_jobs=None, train_sizes=np.linspace(0.1, 1.0, 10)):
    plt.figure()
    plt.title(title)
    if ylim is not None:
        plt.ylim(*ylim)
    plt.xlabel("Exemplos de treinamento")
    plt.ylabel("Pontuação")
    train_sizes, train_scores, test_scores = learning_curve(
        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)
    train_scores_mean = np.mean(train_scores, axis=1)
    train_scores_std = np.std(train_scores, axis=1)
    test_scores_mean = np.mean(test_scores, axis=1)
    test_scores_std = np.std(test_scores, axis=1)
    plt.grid()

    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,
                     train_scores_mean + train_scores_std, alpha=0.1,
                     color="r")
    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,
                     test_scores_mean + test_scores_std, alpha=0.1, color="g")
    plt.plot(train_sizes, train_scores_mean, 'o-', color="r",
             label="Desempenho treinamento")
    plt.plot(train_sizes, test_scores_mean, 'o-', color="g",
             label="Desempenho validação cruzada")

    plt.legend(loc="best")
    return plt

title = "Curvas de Aprendizagem (Logistic Regression SMOTE)"
cv = KFold(n_splits=5)
plot_learning_curve(model_dummy, title, X_train_resampled, y_train_resampled, cv=cv)
plt.show()

import lime
import lime.lime_tabular
from IPython.display import display, HTML

# Certifique-se de que X_train e X_test são arrays numpy ou DataFrames pandas
X_train = X_train.values if isinstance(X_train, pd.DataFrame) else X_train
X_test = X_test.values if isinstance(X_test, pd.DataFrame) else X_test

# Certifique-se de que feature_names é uma lista de strings
feature_names = list(feature_names)  # Convert to list if it's not already

# Criar um explicador LIME
explainer = lime.lime_tabular.LimeTabularExplainer(
    X_train,
    feature_names=feature_names,
    class_names=['Não Inadimplente', 'Inadimplente'],
    discretize_continuous=True
)

# Escolher uma observação para explicar
i = 0
exp = explainer.explain_instance(X_test[i], model_dummy.predict_proba, num_features=len(feature_names))

# Obter o HTML da explicação
exp_html = exp.as_html()

# Adicionar título e customizar estilo
custom_html = f"""
    <div style="font-family: Arial; font-size: 16px; color: black;">
        <h2 style="font-weight: bold;">Explicação da Previsão Local</h2>
        {exp_html}
    </div>
"""

# Mostrar o HTML customizado
display(HTML(custom_html))

# Gerar dados fictícios para avaliação contínua
np.random.seed(42)
num_samples = 1000
new_data = pd.DataFrame({
    'idade_risco': np.random.randint(0, 2, size=num_samples),
    'dias90_risco': np.random.randint(0, 2, size=num_samples),
    'dias60_risco': np.random.randint(0, 2, size=num_samples),
    'dias30_risco': np.random.randint(0, 2, size=num_samples),
    'empretismo_risco': np.random.randint(0, 2, size=num_samples),
    'salario_risco': np.random.randint(0, 2, size=num_samples),
    'dependente_risco': np.random.randint(0, 2, size=num_samples),
    'uso_limite_risco': np.random.randint(0, 2, size=num_samples)
})

# Normalizar os novos dados
scaler = StandardScaler()
new_data_normalized = scaler.fit_transform(new_data)

# Dividir os dados em conjunto de treinamento e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Normalizar os dados de treinamento e teste
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)


# Fazer previsões nos novos dados
y_pred_new = model_dummy.predict(new_data_normalized)

# Imprimir resultados da avaliação contínua
print("Acurácia do modelo Random Forest nos novos dados simulados:", accuracy_score(y_pred_new, np.zeros(num_samples)))
print("\nMatriz de Confusão nos novos dados simulados:\n", confusion_matrix(y_pred_new, np.zeros(num_samples)))
print("\nRelatório de Classificação nos novos dados simulados:\n", classification_report(y_pred_new, np.zeros(num_samples)))

X = df[['idade_risco', 'dias30_risco', 'salario_risco', 'dependente_risco', 'uso_limite_risco']]
y = df['classificacao'] # variavel dependente
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Normalizar dados
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Criar e treinar o modelo de regressão logística
model_dummy1 = LogisticRegression()
model_dummy1.fit(X_train, y_train)

# Fazer previsões e avaliar o modelo
y_pred = model_dummy1.predict(X_test)

#imprimir resultados

print("Acurácia do modelo:", accuracy_score(y_test, y_pred))
print("\nMatriz de Confusão:\n", confusion_matrix(y_test, y_pred))
print("\nRelatório de Classificação:\n", classification_report(y_test, y_pred))


# Visualizar a matriz de confusão
plt.figure(figsize=(8, 6))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues', xticklabels=['Não Inadimplente', 'Inadimplente'], yticklabels=['Não Inadimplente', 'Inadimplente'])
plt.xlabel('Previsão')
plt.ylabel('Verdadeiro')
plt.title('Matriz de Confusão - Regressão Logística')
plt.show()

# Aplicar SMOTE apenas no conjunto de treinamento
smote = SMOTE(random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

# Configurar o GridSearchCV
grid_search = GridSearchCV(estimator=model_dummy1, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)

# Treinar o modelo com GridSearchCV
grid_search.fit(X_train, y_train)

# Melhor combinação de hiperparâmetros
print("Melhores hiperparâmetros:", grid_search.best_params_)

# Usar o melhor modelo para fazer previsões
best_model = grid_search.best_estimator_
y_pred = best_model.predict(X_test)

# Imprimir resultados
print("Acurácia do modelo:", accuracy_score(y_test, y_pred))
print("\nMatriz de Confusão:\n", confusion_matrix(y_test, y_pred))
print("\nRelatório de Classificação:\n", classification_report(y_test, y_pred))

from sklearn.model_selection import learning_curve, KFold

def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None, n_jobs=None, train_sizes=np.linspace(0.1, 1.0, 10)):
    plt.figure()
    plt.title(title)
    if ylim is not None:
        plt.ylim(*ylim)
    plt.xlabel("Exemplos de treinamento")
    plt.ylabel("Pontuação")
    train_sizes, train_scores, test_scores = learning_curve(
        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)
    train_scores_mean = np.mean(train_scores, axis=1)
    train_scores_std = np.std(train_scores, axis=1)
    test_scores_mean = np.mean(test_scores, axis=1)
    test_scores_std = np.std(test_scores, axis=1)
    plt.grid()

    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,
                     train_scores_mean + train_scores_std, alpha=0.1,
                     color="r")
    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,
                     test_scores_mean + test_scores_std, alpha=0.1, color="g")
    plt.plot(train_sizes, train_scores_mean, 'o-', color="r",
             label="Desempenho treinamento")
    plt.plot(train_sizes, test_scores_mean, 'o-', color="g",
             label="Desempenho validação cruzada")

    plt.legend(loc="best")
    return plt

title = "Curvas de Aprendizagem (Logistic Regression SMOTE)"
cv = KFold(n_splits=5)
plot_learning_curve(best_model, title, X_train_resampled, y_train_resampled, cv=cv)
plt.show()

import lime
import lime.lime_tabular
from IPython.display import display, HTML

# Certifique-se de que X_train e X_test são arrays numpy ou DataFrames pandas
X_train = X_train.values if isinstance(X_train, pd.DataFrame) else X_train
X_test = X_test.values if isinstance(X_test, pd.DataFrame) else X_test

# Certifique-se de que feature_names é uma lista de strings
feature_names = list(feature_names)  # Convert to list if it's not already

# Criar um explicador LIME
explainer = lime.lime_tabular.LimeTabularExplainer(
    X_train,
    feature_names=feature_names,
    class_names=['Não Inadimplente', 'Inadimplente'],
    discretize_continuous=True
)

# Escolher uma observação para explicar
i = 0
exp = explainer.explain_instance(X_test[i], best_model.predict_proba, num_features=len(feature_names))

# Obter o HTML da explicação
exp_html = exp.as_html()

# Adicionar título e customizar estilo
custom_html = f"""
    <div style="font-family: Arial; font-size: 16px; color: black;">
        <h2 style="font-weight: bold;">Explicação da Previsão Local</h2>
        {exp_html}
    </div>
"""

# Mostrar o HTML customizado
display(HTML(custom_html))